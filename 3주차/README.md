## 3주차 내용

-----
### [3주차 목표]
* 3주차 목표는 크롤링에 대한 기본 이해입니다.
* 3주차에 필요한 개념들을 소개합니다.

```
예시를 변경합니다. kakaotv가 아니라 4주차까지 연결되게 네이버 실시간 검색어로 변경합니다.
```
> 3주차 개요

    * 오픈 소스에 대한 이해 및 설치 방법 이해
    * HTML 구조 복습 이해
    * 크롤링 코드와 반복문을 이용한 데이터 추출 이해
  
  * ### [1: 오픈 소스에 대한 이해 및 설치 방법 ]
    * 첫 번째 Open source 패키지에 대한 개념인데, Open source란 누구나 다 사용 가능하게 공개 해 놓은 도구들을 뜻하며, 이를 비유적 표현으로 스마트폰 앱, 아니면 공구함으로 설명합니다.
    * 예시로는 따릉이가 적합할 것 같습니다.
    * 뛰는 것보다 따릉이를 타는 것이 더 간편하고, 따릉이는 돈을 좀 내야하지만 위의 경우에는 누구나 다 무료로 사용 가능함을 얘기합니다.
  * [가상환경의 필요성]
    * virtualenv 에 대한 필요성을 언급합니다.
    * 따릉이를 탈 때도, 혼잡한 여의도에서 타는 것보다 내 집 앞에서 타는 것을 비유로 듭니다.
    * 이렇게 작업하는데 있어서 단독적인 공간이 필요한데, 이를 가상환경이라 정의합니다.

    ```
    python -m venv venv
    pip install requests
    pip install beautifulsoup
    ```
    [\^myfootnote]: pip upgrade는 하지 않는 것이...

    > 예상시간 : 5분
  
  * ### 2 [request가 필요한 이유]
    * 각 **라이브러리** 가 무슨 역할을 하는지에 대해 설명해야 합니다.
    * requests의 경우 웹으로 호출해 데이터를 받는다는 기능임을 말합니다. 쉽게 얘기해 해당 웹 페이지에 노크해서 무언가를 얻어오는 식이라는 것을 설명하면 될 것 같습니다.
    * 실제 코드에 표시된 것(2.py) 처럼 bs 넘어가기 전 requests에 대한 기능이 무엇인지를 확인시킵니다.
    * 또힌 get함수에 대해 설명합니다. 원문 그대로 get을 설명하며, **HTTP Response** 임을 밝힙니다.(쉽게 설명해 놓은(get,post,put,delete를 쉽게 설명한 추가적인 자료 역시 준비합니다.) 
    * 현재는 웹에 있는 데이터를 가져오기만 해야하는 것이 get이니  데이터를 가져올 때는 get이라는 함수를 사용한다고 현재 상황에 맞추어 기능을 설명합니다.
  
  > 예상 시간 : 3분
  
  ### 3 [Beautifulsoup 의 역할]

 * beautifulsoup의 기능은 parsing이라 설명합니다.
 * 왜, parsing이 필요한 지, 앞에 문자열과 비교해 설명합니다. 
 * 결국 parsing 은 앞에서 말한 list 형태와 같으며, requests를 통해 가지고 오는 데이터는 bs를 활용해 list 형태로 변형 가능하다고 언급합니다. 이를 parsing 까지 해와야지 만이 원하는 데이터를 가지고 올 수 있음을 얘기합니다.
 * 이는 앞에 있는 list parsing과 유사하다며 앞에서 쳐 보았던 코드로 예시를 듭니다.       
 
        ```
        string1= "park jong hyun"
        print(string1[0])
        print(string1[-1])
        ```         
        
 > 예상 시간: 3분

### 4 [진짜 크롤링 해볼까?]

 * 단계를 나누어보면 다음과 같습니다.
      * [1주차 연습한 html 구조 잡아보기(feat.네이버 실시간 검색어)]
      * [bs 기본 및 html 구조에서의 container(feat. CTRL+F)]
      * bs에서 전달인자와 함수 설명
      * select을 통해 변수 하나에 저장하며
      * 전주차에 학습한 반복문을 통해 select_one으로 추출해 나가는 작업
      * 이를 통해 원하는 순위와 타이틀만을 가지고 오는 작업을 진행합니다.
 > 예상 시간 : 3분 
